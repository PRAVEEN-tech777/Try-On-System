# üíé Enhanced Virtual Jewelry Try-On System

A production-ready Streamlit application combining photorealistic compositing, 3D depth awareness, and occlusion handling for virtual jewelry try-on experiences.

![Status](https://img.shields.io/badge/status-production%20ready-brightgreen)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ‚ú® Features

- **üéØ Intelligent Jewelry Placement**: Automatic positioning using facial/body landmarks
- **üåä 3D-Aware Warping**: Necklaces follow natural neck contours using depth estimation
- **üé≠ Occlusion-Smart Blending**: Jewelry properly layers with hair and clothing
- **üé® Photorealistic Compositing**: Color matching, soft shadows, and smooth alpha blending
- **üîÑ Smart Fallback**: Handles close-ups (FaceMesh) and full-body shots (Pose estimation)
- **‚ö° GPU-Accelerated**: Optional CUDA support for 10√ó speedup
- **üéõÔ∏è Configurable Pipeline**: Tunable parameters for different jewelry types and scenarios

---

## üöÄ Quick Start

### 1. Prerequisites
- Python 3.10+
- 8GB RAM (16GB+ recommended)
- Optional: NVIDIA GPU with CUDA 11.8+

### 2. Installation (2 minutes)

```bash
# Clone or download project
cd jewelry-try-on

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# For GPU (CUDA 11.8)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 3. Run Application (30 seconds)

```bash
streamlit run app.py
```

Open `http://localhost:8501` in your browser. üí´

---

## üìñ Documentation

### For Getting Started
- **[SETUP_GUIDE.md](SETUP_GUIDE.md)** - Installation, configuration, troubleshooting
  - System requirements
  - Step-by-step installation
  - Running the application
  - Deployment options

### For Understanding the System
- **[TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)** - Architecture and design
  - Component overview
  - Detailed algorithm explanations
  - Performance characteristics
  - Extension points

### For Using the API
- **[API_REFERENCE.md](API_REFERENCE.md)** - Class and method documentation
  - Complete API reference
  - Usage examples
  - Common patterns
  - Code snippets

### For Solving Problems
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Issues and optimization
  - Installation problems
  - Runtime issues
  - Performance tuning
  - Debugging commands

---

## üéØ Use Cases

### Virtual Try-On Platforms
```python
result, status = engine.process(
    model_img,
    {'Necklace': jewelry_rgba, 'Earrings': earring_rgba}
)
```

### Jewelry Design Preview
```python
# Process same model with different designs
results = []
for jewelry_design in design_collection:
    result, _ = engine.process(model_img, {'Necklace': jewelry_design})
    results.append(result)
```

### Batch Processing
```python
for model_path in image_paths:
    model_img = cv2.imread(model_path)
    result, status = engine.process(model_img, jewelry_dict)
    cv2.imwrite(f'output/{Path(model_path).stem}.png', result)
```

### Custom Integration
```python
# Use components individually
metrics = detector.detect_anatomy(img_rgb)
depth_map = depth_engine.compute_depth_map(img_pil)
masks = occlusion.get_segmentation_masks(img_pil)

# Create custom pipeline
warped = depth_engine.cylindrical_warp(jewelry, depth_map, ...)
result = compositor.safe_overlay(background, warped, ...)
```

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Streamlit UI Layer              ‚îÇ
‚îÇ  Upload ‚Ä¢ Configure ‚Ä¢ Download      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  EnhancedTryOnEngine (Pipeline)     ‚îÇ
‚îÇ  ‚Ä¢ Anatomy detection                ‚îÇ
‚îÇ  ‚Ä¢ Depth mapping                    ‚îÇ
‚îÇ  ‚Ä¢ Jewelry processing               ‚îÇ
‚îÇ  ‚Ä¢ Occlusion handling               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ       ‚îÇ       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇDepth  ‚îÇ ‚îÇSeg ‚îÇ ‚îÇAnatomy ‚îÇ
‚îÇEngine ‚îÇ ‚îÇ m  ‚îÇ ‚îÇDetector‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ       ‚îÇ       ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇCompositor ‚îÇ
        ‚îÇ ‚Ä¢ Blend   ‚îÇ
        ‚îÇ ‚Ä¢ Color   ‚îÇ
        ‚îÇ ‚Ä¢ Shadow  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇOutput Img ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Components

1. **ModelManager** - Centralized model loading with caching
2. **ImagePreprocessor** - Background removal, RGBA handling
3. **DepthGeometryEngine** - 3D depth mapping and cylindrical warping
4. **OcclusionAnalyzer** - Hair/clothing detection via semantic segmentation
5. **AnatomicalDetector** - Facial/body landmark detection with fallback
6. **AdvancedCompositor** - Photorealistic blending with effects
7. **EnhancedTryOnEngine** - Main orchestration pipeline

---

## üîß Configuration

### Via UI Sidebar

```
Configuration
‚îú‚îÄ‚îÄ Sizing
‚îÇ   ‚îú‚îÄ‚îÄ Necklace Width: 2.0-4.0
‚îÇ   ‚îî‚îÄ‚îÄ Earring Size: 0.5-1.2
‚îú‚îÄ‚îÄ Blending
‚îÇ   ‚îú‚îÄ‚îÄ Color Matching: 0.0-1.0
‚îÇ   ‚îú‚îÄ‚îÄ Edge Softness: 1-10
‚îÇ   ‚îî‚îÄ‚îÄ Shadow Strength: 0.0-0.5
‚îî‚îÄ‚îÄ Detection
    ‚îî‚îÄ‚îÄ Confidence: 0.3-1.0
```

### Programmatically

```python
config = TryOnConfig(
    necklace_width_ratio=3.5,
    color_match_strength=0.3,
    edge_feather_radius=5,
    shadow_intensity=0.2,
    use_gpu=True
)
```

---

## üìä Performance

| Scenario | GPU (RTX 3060) | CPU (i7-12700K) |
|----------|---|---|
| 1080√ó1080, Necklace | 4-5s | 45-60s |
| 1080√ó1080, Multiple | 6-8s | 60-75s |
| 640√ó640, Single | 2-3s | 20-25s |
| Model Load | 3-5s | 15-20s |

**GPU significantly recommended for interactive use.**

---

## üé® Model Assets

### Models Used

| Component | Model | Size | Source |
|-----------|-------|------|--------|
| Depth | depth-anything-small | 100MB | Hugging Face |
| Segmentation | segformer_b2_clothes | 350MB | Hugging Face |
| Face | MediaPipe FaceMesh | 5MB | Google |
| Pose | MediaPipe Pose | 5MB | Google |

### Auto-Download

All models download automatically on first run (~450MB total).

```bash
# Manual download if needed:
huggingface-cli download LiheYoung/depth-anything-small-hf
huggingface-cli download mattmdjaga/segformer_b2_clothes
```

---

## üìã Requirements

```
Core:
- streamlit>=1.39.0
- opencv-python>=4.8.1
- numpy>=1.24.3
- pillow>=10.1.0

Deep Learning:
- torch>=2.0.1
- transformers>=4.35.2
- mediapipe>=0.10.9

Processing:
- rembg>=0.0.55
- dataclasses-json>=0.6.1
```

See `requirements.txt` for full list with pinned versions.

---

## üõ†Ô∏è Troubleshooting

### "No module named 'streamlit'"
```bash
pip install -r requirements.txt
```

### CUDA out of memory
```python
config.use_gpu = False  # Fall back to CPU
```

### Models not downloading
```bash
huggingface-cli download LiheYoung/depth-anything-small-hf
huggingface-cli download mattmdjaga/segformer_b2_clothes
```

### Jewelry appears misaligned
```python
config.necklace_y_offset = 2.5  # Adjust positioning
config.necklace_width_ratio = 3.0  # Adjust sizing
```

See **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** for comprehensive solutions.

---

## üìö API Usage Examples

### Basic Usage
```python
from app import EnhancedTryOnEngine, TryOnConfig, ModelManager
import cv2
from PIL import Image
import numpy as np

# Initialize
config = TryOnConfig()
models = ModelManager.load_all_models(config)
engine = EnhancedTryOnEngine(models, config)

# Load images
model_img = cv2.imread('model.jpg')
jewelry = np.array(Image.open('necklace.png').convert('RGBA'))

# Process
result, status = engine.process(
    model_img,
    {'Necklace': jewelry, 'Earrings': None, 'Nose Pin': None}
)

# Save
cv2.imwrite('output.png', result)
print(status)  # ‚úÖ Success (FaceMesh): Necklace
```

### Batch Processing
```python
from pathlib import Path

for img_path in Path('images/').glob('*.jpg'):
    model_img = cv2.imread(str(img_path))
    result, status = engine.process(model_img, jewelry_dict)
    cv2.imwrite(f'output/{img_path.stem}_result.png', result)
    print(f"{img_path.name}: {status}")
```

### Custom Configuration
```python
# For delicate jewelry
config = TryOnConfig(
    necklace_width_ratio=2.5,
    color_match_strength=0.2,
    shadow_intensity=0.1,
    edge_feather_radius=5
)
```

See **[API_REFERENCE.md](API_REFERENCE.md)** for complete documentation.

---

## üåê Deployment

### Docker
```bash
docker build -t jewelry-try-on .
docker run -p 8501:8501 jewelry-try-on
```

### Streamlit Cloud
1. Push to GitHub
2. Connect at https://streamlit.io/cloud
3. Select repository and deploy

### AWS/GCP/Azure
Deploy Docker image on compute instances with GPU support.

---

## ü§ù Contributing

Contributions welcome! Areas for enhancement:
- Additional jewelry types (rings, bracelets)
- Real-time webcam processing
- Multi-person support
- Advanced texture mapping
- Performance optimizations

---

## üìÑ License

MIT License - see LICENSE file

---

## üîó Quick Links

- **Setup**: [SETUP_GUIDE.md](SETUP_GUIDE.md)
- **Architecture**: [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)
- **API**: [API_REFERENCE.md](API_REFERENCE.md)
- **Help**: [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

---

## üìû Support

- Check [TROUBLESHOOTING.md](TROUBLESHOOTING.md) first
- Review [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md) for design details
- See [API_REFERENCE.md](API_REFERENCE.md) for usage examples

---

## üéì References

### Depth Estimation
- "Depth Anything" (2024) - [Paper](https://arxiv.org/abs/2401.10891)
- Model: `LiheYoung/depth-anything-small-hf`

### Semantic Segmentation
- SegFormer B2 - [Paper](https://arxiv.org/abs/2105.15203)
- Model: `mattmdjaga/segformer_b2_clothes`

### Face Landmarks
- MediaPipe FaceMesh - [Documentation](https://mediapipe.dev)

### Pose Estimation
- MediaPipe Pose - [Documentation](https://mediapipe.dev)

---

## üìà Roadmap

- [ ] Real-time camera mode
- [ ] Multi-person support
- [ ] Ring virtual try-on
- [ ] Bracelet support
- [ ] Advanced lighting estimation
- [ ] Texture and material simulation
- [ ] Mobile app
- [ ] REST API endpoint

---

**Version**: 1.0  
**Status**: ‚úÖ Production Ready  
**Last Updated**: November 2024

---

## Quick Decision Tree

**Just want to use it?**
‚Üí Follow [SETUP_GUIDE.md](SETUP_GUIDE.md)

**Want to understand how it works?**
‚Üí Read [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)

**Want to use the API?**
‚Üí Check [API_REFERENCE.md](API_REFERENCE.md)

**Something broken?**
‚Üí See [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

---

Happy try-on! üíé‚ú®
